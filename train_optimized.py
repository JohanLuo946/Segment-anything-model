#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ğŸ”¥ SAMå£°å¸¦ç—…ç¶åˆ†å‰² - è€å“¥å®šåˆ¶ä¼˜åŒ–ç‰ˆæœ¬ ğŸ”¥
ä¸“æ²»ç±»åˆ«ä¸å¹³è¡¡ï¼å°ç›®æ ‡åˆ†å‰²æ€æ‰‹é”ï¼
ä½œè€…ï¼šå°æŸ¯ï¼ˆèµ„æ·±æŠ€æœ¯è€å“¥ï¼‰
"""

import os
import sys
import time
import json
import random
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler
from torch.cuda.amp import GradScaler, autocast
import cv2
from PIL import Image
import matplotlib.pyplot as plt
from sklearn.metrics import precision_recall_fscore_support
import logging
from tqdm import tqdm
import gc
from collections import defaultdict, Counter

# è®¾ç½®æ—¥å¿— - è€å“¥é£æ ¼
logging.basicConfig(level=logging.INFO, format='%(asctime)s -  - %(message)s')
logger = logging.getLogger(__name__)

# ===== ğŸ’ª ç¡¬æ ¸ä¼˜åŒ–é…ç½® =====
class OptimizedConfig:
    """è€å“¥çš„æ€æ‰‹çº§é…ç½® - ä¸“æ²»ç±»åˆ«ä¸å¹³è¡¡ï¼"""
    
    # è·¯å¾„é…ç½®
    TRAIN_IMAGES_DIR = "/root/autodl-tmp/SAM/data/train/images"
    TRAIN_MASKS_DIR = "/root/autodl-tmp/SAM/data/train/masks"
    VAL_IMAGES_DIR = "/root/autodl-tmp/SAM/data/val/images"
    VAL_MASKS_DIR = "/root/autodl-tmp/SAM/data/val/masks"
    SAM_MODEL_PATH = "/root/autodl-tmp/SAM/pre_models/sam_vit_b_01ec64.pth"  # ä½¿ç”¨ViT-bæ¨¡å‹
    RESULTS_DIR = "/root/autodl-tmp/SAM/results/models/run_2"
    
    # åŸºç¡€é…ç½®
    NUM_CLASSES = 6
    IMAGE_SIZE = 1024
    BATCH_SIZE = 2      
    NUM_WORKERS = 4
    
    # ç±»åˆ«æ˜ å°„ - è€å“¥æŒ‡å®šçš„æ­£ç¡®æ˜ å°„
    ID_MAPPING = {
        0: 0,    # èƒŒæ™¯
        170: 1,  # å·¦å£°å¸¦
        184: 2,  # å³å£°å¸¦
        105: 3,  # å£°å¸¦å°ç»“
        23: 4,   # å£°å¸¦ç™½æ–‘
        146: 5,  # å£°å¸¦ä¹³å¤´çŠ¶ç˜¤
    }
    
    CLASS_NAMES = [
        "èƒŒæ™¯", "å·¦å£°å¸¦", "å³å£°å¸¦", "å£°å¸¦å°ç»“", "å£°å¸¦ç™½æ–‘", "å£°å¸¦ä¹³å¤´çŠ¶ç˜¤"
    ]
    
    # ğŸ”¥ åŠ¨æ€æƒé‡ç­–ç•¥ - æ ¹æ®ç±»åˆ«éš¾åº¦è‡ªé€‚åº”è°ƒæ•´
    INITIAL_CLASS_WEIGHTS = [0.1, 1.0, 1.0, 30.0, 35.0, 32.0]  # ç—…ç¶æƒé‡çˆ†ç‚¸å¼æå‡ï¼
    DYNAMIC_WEIGHT_UPDATE = True    # å¼€å¯åŠ¨æ€æƒé‡è°ƒæ•´
    
    # è®­ç»ƒé…ç½® - è€å“¥ä¼˜åŒ–ç‰ˆ
    NUM_EPOCHS = 150         # å¤šè®­ç»ƒä¸€äº›epochï¼Œç»™ç—…ç¶å­¦ä¹ æ—¶é—´
    LEARNING_RATE = 2e-4    # ç¨å¾®æé«˜å­¦ä¹ ç‡
    WEIGHT_DECAY = 1e-4
    GRADIENT_ACCUMULATION_STEPS = 2  # å‡å°‘æ¢¯åº¦ç´¯ç§¯ï¼Œæ›´é¢‘ç¹æ›´æ–°
    
    # SAMé…ç½®
    SAM_MODEL_TYPE = "vit_b"
    PIXEL_MEAN = [123.675, 116.28, 103.53]
    PIXEL_STD = [58.395, 57.12, 57.375]
    
    # è®¾å¤‡é…ç½®
    DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
    MIXED_PRECISION = True
    
    # ğŸš€ ä¼˜åŒ–ç­–ç•¥å¼€å…³
    USE_FOCAL_LOSS = True           # Focal Loss ä¸“æ²»éš¾åˆ†ç±»
    USE_DICE_LOSS = True            # Dice Loss ä¸“æ²»å°ç›®æ ‡
    USE_SMART_SAMPLING = True       # æ™ºèƒ½é‡‡æ ·ï¼Œç—…ç¶æ ·æœ¬ä¼˜å…ˆ
    USE_MULTI_SCALE_LOSS = False    # å¤šå°ºåº¦æŸå¤± - SAMä¸æ”¯æŒï¼Œæš‚æ—¶å…³é—­
    USE_LABEL_SMOOTHING = True      # æ ‡ç­¾å¹³æ»‘ï¼Œé˜²è¿‡æ‹Ÿåˆ
    
    # Focal Loss å‚æ•°
    FOCAL_ALPHA = [0.1, 1.0, 1.0, 4.0, 5.0, 4.5]  # å„ç±»åˆ«focalæƒé‡
    FOCAL_GAMMA = 2.0               # éš¾åº¦å…³æ³¨å‚æ•°
    
    # æ™ºèƒ½é‡‡æ ·å‚æ•°
    LESION_OVERSAMPLE_FACTOR = 5.0  # ç—…ç¶æ ·æœ¬è¿‡é‡‡æ ·å€æ•°
    BACKGROUND_UNDERSAMPLE_FACTOR = 0.3  # èƒŒæ™¯æ ·æœ¬æ¬ é‡‡æ ·
    
    # å¤šå°ºåº¦è®­ç»ƒå‚æ•°
    MULTI_SCALE_SIZES = [512, 768, 1024]  # å¤šå°ºåº¦è®­ç»ƒå°ºå¯¸
    SCALE_CHANGE_FREQUENCY = 10     # æ¯10ä¸ªepochåˆ‡æ¢ä¸€æ¬¡å°ºåº¦
    
    # æ˜¾å­˜ä¼˜åŒ–
    CLEAR_CACHE_EVERY = 3
    PIN_MEMORY = False
    
    # ä¿å­˜å’Œè¯„ä¼°
    SAVE_EVERY = 10
    EVAL_EVERY = 1          # æ›´é¢‘ç¹éªŒè¯ï¼ŒåŠæ—¶å‘ç°é—®é¢˜
    EARLY_STOPPING_PATIENCE = 20

config = OptimizedConfig()

# ===== ğŸ¯ æ™ºèƒ½æ•°æ®é›†ç±» - è€å“¥ç‰¹åˆ¶ =====
class SmartVocalFoldDataset(Dataset):
    """è€å“¥çš„æ™ºèƒ½æ•°æ®é›† - ä¸“é—¨ç…§é¡¾ç—…ç¶æ ·æœ¬ï¼"""
    
    def __init__(self, images_dir, masks_dir, is_train=True, current_epoch=0):
        self.images_dir = images_dir
        self.masks_dir = masks_dir
        self.is_train = is_train
        self.current_epoch = current_epoch
        
        # è·å–å›¾åƒæ–‡ä»¶
        self.image_files = []
        for file in os.listdir(images_dir):
            if file.lower().endswith(('.jpg', '.jpeg', '.png')):
                mask_file = file.replace('.jpg', '.png').replace('.jpeg', '.png')
                mask_path = os.path.join(masks_dir, mask_file)
                if os.path.exists(mask_path):
                    self.image_files.append(file)
        
        logger.info(f"æ‰¾åˆ° {len(self.image_files)} ä¸ªå›¾åƒ-æ©ç å¯¹")
        
        # ğŸ”¥ åˆ†ææ ·æœ¬åˆ†å¸ƒï¼Œåˆ¶å®šé‡‡æ ·ç­–ç•¥
        if is_train and config.USE_SMART_SAMPLING:
            self.analyze_sample_distribution()
    
    def analyze_sample_distribution(self):
        """åˆ†ææ ·æœ¬åˆ†å¸ƒï¼Œè€å“¥è¦çŸ¥å·±çŸ¥å½¼ï¼"""
        logger.info("è€å“¥æ­£åœ¨åˆ†ææ ·æœ¬åˆ†å¸ƒ...")
        
        self.sample_weights = []
        lesion_samples = 0
        background_only_samples = 0
        
        for image_file in tqdm(self.image_files, desc="åˆ†ææ ·æœ¬"):
            mask_file = image_file.replace('.jpg', '.png').replace('.jpeg', '.png')
            mask_path = os.path.join(self.masks_dir, mask_file)
            mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)
            
            # åº”ç”¨IDæ˜ å°„
            mapped_mask = self.apply_id_mapping(mask)
            
            # æ£€æŸ¥æ˜¯å¦åŒ…å«ç—…ç¶ï¼ˆç±»åˆ«3,4,5ï¼‰
            unique_ids = np.unique(mapped_mask)
            has_lesion = any(id in [3, 4, 5] for id in unique_ids)
            
            if has_lesion:
                # åŒ…å«ç—…ç¶çš„æ ·æœ¬ï¼Œæƒé‡çˆ†ç‚¸ï¼
                weight = config.LESION_OVERSAMPLE_FACTOR
                lesion_samples += 1
            elif len(unique_ids) == 1 and unique_ids[0] == 0:
                # çº¯èƒŒæ™¯æ ·æœ¬ï¼Œæƒé‡å‰Šå‡
                weight = config.BACKGROUND_UNDERSAMPLE_FACTOR
                background_only_samples += 1
            else:
                # æ™®é€šæ ·æœ¬ï¼Œæ­£å¸¸æƒé‡
                weight = 1.0
            
            self.sample_weights.append(weight)
        
        logger.info(f"è€å“¥åˆ†æå®Œæ¯•ï¼š")
        logger.info(f"  ğŸ”¥ ç—…ç¶æ ·æœ¬: {lesion_samples} ä¸ª (æƒé‡x{config.LESION_OVERSAMPLE_FACTOR})")
        logger.info(f"  ğŸ˜´ çº¯èƒŒæ™¯æ ·æœ¬: {background_only_samples} ä¸ª (æƒé‡x{config.BACKGROUND_UNDERSAMPLE_FACTOR})")
        logger.info(f"  ğŸ˜Š æ™®é€šæ ·æœ¬: {len(self.image_files)-lesion_samples-background_only_samples} ä¸ª")
    
    def get_weighted_sampler(self):
        """è·å–æ™ºèƒ½é‡‡æ ·å™¨ - è€å“¥çš„ç§˜å¯†æ­¦å™¨"""
        if hasattr(self, 'sample_weights'):
            return WeightedRandomSampler(
                weights=self.sample_weights,
                num_samples=len(self.sample_weights),
                replacement=True
            )
        return None
    
    def apply_id_mapping(self, mask):
        """åº”ç”¨IDæ˜ å°„è½¬æ¢"""
        mapped_mask = np.zeros_like(mask)
        for original_id, new_id in config.ID_MAPPING.items():
            mapped_mask[mask == original_id] = new_id
        
        # æœªçŸ¥IDæ˜ å°„ä¸ºèƒŒæ™¯
        unknown_mask = np.ones_like(mask, dtype=bool)
        for original_id in config.ID_MAPPING.keys():
            unknown_mask &= (mask != original_id)
        mapped_mask[unknown_mask] = 0
        
        return mapped_mask
    
    def smart_augmentation(self, image, mask):
        """è€å“¥çš„æ™ºèƒ½å¢å¼º - ä¸“é—¨ç…§é¡¾ç—…ç¶"""
        if not self.is_train:
            return image, mask
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«ç—…ç¶
        unique_ids = np.unique(mask)
        has_lesion = any(id in [3, 4, 5] for id in unique_ids)
        
        if has_lesion:
            # ç—…ç¶æ ·æœ¬ï¼Œæ¸©å’Œå¢å¼ºï¼Œä¿æŠ¤ç»†èŠ‚
            if random.random() < 0.3:
                # å°å¹…æ—‹è½¬
                angle = random.uniform(-5, 5)
                h, w = image.shape[:2]
                center = (w//2, h//2)
                M = cv2.getRotationMatrix2D(center, angle, 1.0)
                image = cv2.warpAffine(image, M, (w, h))
                mask = cv2.warpAffine(mask, M, (w, h), flags=cv2.INTER_NEAREST)
            
            if random.random() < 0.4:
                # äº®åº¦å¾®è°ƒ
                factor = random.uniform(0.9, 1.1)
                image = np.clip(image * factor, 0, 255).astype(np.uint8)
        else:
            # éç—…ç¶æ ·æœ¬ï¼Œå¯ä»¥æ›´æ¿€è¿›çš„å¢å¼º
            if random.random() < 0.5:
                # æ›´å¤§èŒƒå›´æ—‹è½¬
                angle = random.uniform(-10, 10)
                h, w = image.shape[:2]
                center = (w//2, h//2)
                M = cv2.getRotationMatrix2D(center, angle, 1.0)
                image = cv2.warpAffine(image, M, (w, h))
                mask = cv2.warpAffine(mask, M, (w, h), flags=cv2.INTER_NEAREST)
        
        return image, mask
    
    def __len__(self):
        return len(self.image_files)
    
    def __getitem__(self, idx):
        # ğŸ”¥ SAMæ¨¡å‹è¦æ±‚å›ºå®šå°ºå¯¸1024x1024
        current_size = config.IMAGE_SIZE
        
        # åŠ è½½å›¾åƒ
        image_file = self.image_files[idx]
        image_path = os.path.join(self.images_dir, image_file)
        image = cv2.imread(image_path)
        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        
        # åŠ è½½æ©ç 
        mask_file = image_file.replace('.jpg', '.png').replace('.jpeg', '.png')
        mask_path = os.path.join(self.masks_dir, mask_file)
        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)
        
        # åº”ç”¨IDæ˜ å°„
        mask = self.apply_id_mapping(mask)
        
        # æ™ºèƒ½å¢å¼º
        image, mask = self.smart_augmentation(image, mask)
        
        # è°ƒæ•´å°ºå¯¸
        image = cv2.resize(image, (current_size, current_size))
        mask = cv2.resize(mask, (current_size, current_size), interpolation=cv2.INTER_NEAREST)
        
        # è½¬æ¢ä¸ºtensor
        image = torch.from_numpy(image).permute(2, 0, 1).float() / 255.0
        mask = torch.from_numpy(mask).long()
        
        # æ ‡å‡†åŒ–
        mean = torch.tensor(config.PIXEL_MEAN).view(3, 1, 1) / 255.0
        std = torch.tensor(config.PIXEL_STD).view(3, 1, 1) / 255.0
        image = (image - mean) / std
        
        return image, mask, image_file

# ===== ğŸ”¥ æ€æ‰‹çº§æŸå¤±å‡½æ•° - è€å“¥ç‰¹åˆ¶ =====
class KillerLoss(nn.Module):
    """è€å“¥çš„æ€æ‰‹çº§æŸå¤±å‡½æ•° - ä¸“æ²»ç±»åˆ«ä¸å¹³è¡¡ï¼"""
    
    def __init__(self, class_weights=None, focal_alpha=None, focal_gamma=2.0):
        super().__init__()
        self.class_weights = class_weights
        self.focal_alpha = focal_alpha
        self.focal_gamma = focal_gamma
        
        # åŸºç¡€æŸå¤±å‡½æ•°
        if class_weights is not None:
            self.ce_loss = nn.CrossEntropyLoss(weight=torch.tensor(class_weights).float())
        else:
            self.ce_loss = nn.CrossEntropyLoss()
        
        logger.info("æ€æ‰‹çº§æŸå¤±å‡½æ•°è£…é…å®Œæ¯•ï¼ğŸ”¥")
    
    def focal_loss(self, predictions, targets):
        """Focal Loss - ä¸“æ²»éš¾åˆ†ç±»æ ·æœ¬"""
        ce_loss = F.cross_entropy(predictions, targets, reduction='none')
        pt = torch.exp(-ce_loss)
        
        # è®¡ç®—alphaæƒé‡
        if self.focal_alpha is not None:
            alpha_t = torch.tensor(self.focal_alpha).to(predictions.device)[targets]
        else:
            alpha_t = 1.0
        
        # Focal Losså…¬å¼
        focal_loss = alpha_t * (1 - pt) ** self.focal_gamma * ce_loss
        return focal_loss.mean()
    
    def dice_loss(self, predictions, targets):
        """Dice Loss - ä¸“æ²»å°ç›®æ ‡"""
        smooth = 1e-5
        predictions = torch.softmax(predictions, dim=1)
        
        dice_loss = 0
        for class_idx in range(config.NUM_CLASSES):
            pred_class = predictions[:, class_idx]
            target_class = (targets == class_idx).float()
            
            intersection = (pred_class * target_class).sum()
            union = pred_class.sum() + target_class.sum()
            
            dice = (2 * intersection + smooth) / (union + smooth)
            dice_loss += 1 - dice
        
        return dice_loss / config.NUM_CLASSES
    
    def forward(self, predictions, targets):
        loss_dict = {}
        total_loss = 0
        
        # 1. CrossEntropy Loss (åŸºç¡€)
        if config.USE_LABEL_SMOOTHING:
            # æ ‡ç­¾å¹³æ»‘ï¼Œé˜²è¿‡æ‹Ÿåˆ
            ce_loss = F.cross_entropy(predictions, targets, label_smoothing=0.1)
        else:
            ce_loss = self.ce_loss(predictions, targets)
        loss_dict['ce_loss'] = ce_loss.item()
        total_loss += 0.4 * ce_loss
        
        # 2. Focal Loss (éš¾åˆ†ç±»æ ·æœ¬)
        if config.USE_FOCAL_LOSS:
            focal_loss = self.focal_loss(predictions, targets)
            loss_dict['focal_loss'] = focal_loss.item()
            total_loss += 0.4 * focal_loss
        
        # 3. Dice Loss (å°ç›®æ ‡)
        if config.USE_DICE_LOSS:
            dice_loss = self.dice_loss(predictions, targets)
            loss_dict['dice_loss'] = dice_loss.item()
            total_loss += 0.2 * dice_loss
        
        return total_loss, loss_dict

# ===== ğŸš€ å¼ºåŒ–SAMæ¨¡å‹ - è€å“¥æ”¹è£…ç‰ˆ =====
class EnhancedSAMModel(nn.Module):
    """è€å“¥çš„å¼ºåŒ–SAMæ¨¡å‹ - ä¸“æ²»å°ç›®æ ‡ï¼"""
    
    def __init__(self, sam_model, num_classes):
        super().__init__()
        self.sam = sam_model
        self.num_classes = num_classes
        
        # ğŸ”¥ å¤šå°ºåº¦ç‰¹å¾èåˆåˆ†å‰²å¤´
        self.segmentation_head = nn.Sequential(
            # ç¬¬ä¸€å±‚ï¼šç‰¹å¾æå–
            nn.Conv2d(256, 128, kernel_size=3, padding=1),
            nn.BatchNorm2d(128),
            nn.ReLU(inplace=True),
            
            # ç¬¬äºŒå±‚ï¼šç‰¹å¾ç»†åŒ–
            nn.Conv2d(128, 64, kernel_size=3, padding=1),
            nn.BatchNorm2d(64),
            nn.ReLU(inplace=True),
            
            # ç¬¬ä¸‰å±‚ï¼šåˆ†ç±»è¾“å‡º
            nn.Conv2d(64, num_classes, kernel_size=1)
        )
        
        # ğŸ¯ æ³¨æ„åŠ›æ¨¡å— - è®©æ¨¡å‹ä¸»åŠ¨å…³æ³¨ç—…ç¶
        self.attention = nn.Sequential(
            nn.Conv2d(256, 64, kernel_size=1),
            nn.ReLU(inplace=True),
            nn.Conv2d(64, 1, kernel_size=1),
            nn.Sigmoid()
        )
        
        # å†»ç»“SAMçš„éƒ¨åˆ†å‚æ•°ï¼Œåªå¾®è°ƒå…³é”®éƒ¨åˆ†
        self.freeze_sam_components()
        
        logger.info("å¼ºåŒ–SAMæ¨¡å‹æ”¹è£…å®Œæ¯•ï¼ä¸“æ²»å°ç›®æ ‡ï¼ğŸ¯")
    
    def freeze_sam_components(self):
        """å†»ç»“SAMçš„å¤§éƒ¨åˆ†å‚æ•°ï¼Œåªè®­ç»ƒå¿…è¦çš„éƒ¨åˆ†"""
        # å†»ç»“image_encoderçš„å‰é¢å‡ å±‚
        layers = list(self.sam.image_encoder.children())
        for i, layer in enumerate(layers[:-3]):  # åªè§£å†»æœ€å3å±‚
            for param in layer.parameters():
                param.requires_grad = False
        
        logger.info("SAMå‚æ•°å†»ç»“å®Œæ¯•ï¼Œåªè®­ç»ƒå…³é”®éƒ¨åˆ†ï¼")
    
    def forward(self, images):
        batch_size = images.shape[0]
        
        # SAMå›¾åƒç¼–ç 
        image_embeddings = self.sam.image_encoder(images)
        
        # ğŸ¯ æ³¨æ„åŠ›å¢å¼º
        attention_map = self.attention(image_embeddings)
        enhanced_features = image_embeddings * attention_map
        
        # å¤šå°ºåº¦åˆ†å‰²
        segmentation_logits = self.segmentation_head(enhanced_features)
        
        # ä¸Šé‡‡æ ·åˆ°åŸå§‹å°ºå¯¸
        segmentation_logits = F.interpolate(
            segmentation_logits,
            size=(images.shape[2], images.shape[3]),
            mode="bilinear",
            align_corners=False,
        )
        
        # è™šæ‹ŸIoUé¢„æµ‹ï¼ˆä¿æŒå…¼å®¹æ€§ï¼‰
        iou_predictions = torch.ones(batch_size, 1).to(images.device) * 0.8
        
        return segmentation_logits, iou_predictions

# ===== ğŸ§  æ™ºèƒ½æŒ‡æ ‡è®¡ç®—å™¨ - è€å“¥å®šåˆ¶ =====
class SmartMetrics:
    """è€å“¥çš„æ™ºèƒ½æŒ‡æ ‡è®¡ç®—å™¨ - ä¸“é—¨ç›‘æ§ç—…ç¶å­¦ä¹ è¿›åº¦"""
    
    def __init__(self, num_classes, class_names):
        self.num_classes = num_classes
        self.class_names = class_names
        self.reset()
    
    def reset(self):
        self.class_ious = np.zeros(self.num_classes)
        self.class_dices = np.zeros(self.num_classes)
        self.class_counts = np.zeros(self.num_classes)
        self.total_correct = 0
        self.total_pixels = 0
        
        # ğŸ”¥ ä¸“é—¨ç›‘æ§ç—…ç¶è¿›åº¦
        self.lesion_progress = {
            'sdxj': [],  # å£°å¸¦å°ç»“
            'sdbb': [],  # å£°å¸¦ç™½æ–‘  
            'rtzl': []   # å£°å¸¦ä¹³å¤´çŠ¶ç˜¤
        }
    
    def update(self, predictions, targets):
        predictions = torch.argmax(predictions, dim=1)
        
        # æ•´ä½“å‡†ç¡®ç‡
        self.total_correct += (predictions == targets).sum().item()
        self.total_pixels += targets.numel()
        
        # å„ç±»åˆ«IoUå’ŒDice
        for class_idx in range(self.num_classes):
            pred_mask = (predictions == class_idx)
            target_mask = (targets == class_idx)
            
            intersection = (pred_mask & target_mask).sum().item()
            union = (pred_mask | target_mask).sum().item()
            pred_sum = pred_mask.sum().item()
            target_sum = target_mask.sum().item()
            
            if union > 0:
                iou = intersection / union
                self.class_ious[class_idx] += iou
                self.class_counts[class_idx] += 1
            
            if pred_sum + target_sum > 0:
                dice = 2 * intersection / (pred_sum + target_sum)
                self.class_dices[class_idx] += dice
        
        # ğŸ”¥ ä¸“é—¨ç›‘æ§ç—…ç¶ç±»åˆ«è¿›åº¦
        lesion_map = {3: 'sdxj', 4: 'sdbb', 5: 'rtzl'}
        for class_idx, lesion_name in lesion_map.items():
            if self.class_counts[class_idx] > 0:
                current_iou = self.class_ious[class_idx] / self.class_counts[class_idx]
                self.lesion_progress[lesion_name].append(current_iou)
    
    def compute(self):
        accuracy = self.total_correct / self.total_pixels if self.total_pixels > 0 else 0
        
        # è®¡ç®—å„ç±»åˆ«æŒ‡æ ‡
        class_ious = {}
        class_dices = {}
        
        valid_ious = []
        for i, name in enumerate(self.class_names):
            if self.class_counts[i] > 0:
                iou = self.class_ious[i] / self.class_counts[i]
                dice = self.class_dices[i] / self.class_counts[i]
                class_ious[name] = iou
                class_dices[name] = dice
                valid_ious.append(iou)
            else:
                class_ious[name] = 0.0
                class_dices[name] = 0.0
        
        mean_iou = np.mean(valid_ious) if valid_ious else 0
        mean_dice = np.mean([v for v in class_dices.values() if v > 0])
        
        # ğŸ”¥ ç—…ç¶ä¸“é¡¹æŠ¥å‘Š
        lesion_report = {}
        for lesion_name, progress in self.lesion_progress.items():
            if progress:
                lesion_report[lesion_name] = {
                    'current_iou': progress[-1],
                    'trend': 'improving' if len(progress) > 1 and progress[-1] > progress[0] else 'stable'
                }
        
        return {
            'accuracy': accuracy,
            'mIoU': mean_iou,
            'mDice': mean_dice,
            'class_ious': class_ious,
            'class_dices': class_dices,
            'lesion_report': lesion_report
        }

# ===== ğŸ® è¶…çº§è®­ç»ƒå™¨ - è€å“¥æ“åˆ€ =====
class SuperTrainer:
    """è€å“¥çš„è¶…çº§è®­ç»ƒå™¨ - æ™ºèƒ½è°ƒå‚ï¼Œè‡ªåŠ¨ä¼˜åŒ–ï¼"""
    
    def __init__(self):
        self.device = torch.device(config.DEVICE)
        self.scaler = GradScaler() if config.MIXED_PRECISION else None
        
        # åˆ›å»ºç»“æœç›®å½•
        os.makedirs(config.RESULTS_DIR, exist_ok=True)
        os.makedirs(os.path.join(config.RESULTS_DIR, "models"), exist_ok=True)
        os.makedirs(os.path.join(config.RESULTS_DIR, "logs"), exist_ok=True)
        
        logger.info("ğŸš€ è€å“¥çš„è¶…çº§è®­ç»ƒå™¨å¯åŠ¨ï¼")
        
        # ğŸ”¥ è®­ç»ƒçŠ¶æ€ - å¿…é¡»åœ¨setup_trainingä¹‹å‰åˆå§‹åŒ–ï¼
        self.best_miou = 0.0
        self.patience_counter = 0
        self.current_weights = config.INITIAL_CLASS_WEIGHTS.copy()
        
        # åˆå§‹åŒ–ç»„ä»¶
        self.setup_model()
        self.setup_data()
        self.setup_training()
        
        # è®°å½•è®­ç»ƒå†å²
        self.history = {
            'train_loss': [], 'val_loss': [],
            'train_miou': [], 'val_miou': [],
            'lesion_ious': {'sdxj': [], 'sdbb': [], 'rtzl': []}
        }
    
    def setup_model(self):
        """è®¾ç½®æ¨¡å‹"""
        logger.info("è€å“¥æ­£åœ¨è£…é…SAMæ¨¡å‹...")
        
        try:
            from segment_anything import sam_model_registry
            sam = sam_model_registry[config.SAM_MODEL_TYPE](checkpoint=config.SAM_MODEL_PATH)
            sam.to(self.device)
            
            self.model = EnhancedSAMModel(sam, config.NUM_CLASSES)
            self.model.to(self.device)
            
            # è®¡ç®—æ¨¡å‹å‚æ•°
            total_params = sum(p.numel() for p in self.model.parameters())
            trainable_params = sum(p.numel() for p in self.model.parameters() if p.requires_grad)
            
            logger.info(f"SAMæ¨¡å‹è£…é…å®Œæ¯•ï¼")
            logger.info(f"  æ€»å‚æ•°: {total_params:,}")
            logger.info(f"  å¯è®­ç»ƒå‚æ•°: {trainable_params:,}")
            logger.info(f"  å‚æ•°å†»ç»“ç‡: {100*(1-trainable_params/total_params):.1f}%")
            
        except ImportError:
            logger.error("segment_anythingæ²¡è£…ï¼Œæ­£åœ¨å®‰è£…...")
            os.system("pip install segment-anything")
            from segment_anything import sam_model_registry
            sam = sam_model_registry[config.SAM_MODEL_TYPE](checkpoint=config.SAM_MODEL_PATH)
            sam.to(self.device)
            self.model = EnhancedSAMModel(sam, config.NUM_CLASSES)
            self.model.to(self.device)
    
    def setup_data(self):
        """è®¾ç½®æ•°æ®åŠ è½½å™¨"""
        logger.info("è€å“¥æ­£åœ¨å‡†å¤‡æ•°æ®...")
        
        # åˆ›å»ºæ•°æ®é›†
        self.train_dataset = SmartVocalFoldDataset(
            config.TRAIN_IMAGES_DIR,
            config.TRAIN_MASKS_DIR,
            is_train=True
        )
        
        self.val_dataset = SmartVocalFoldDataset(
            config.VAL_IMAGES_DIR,
            config.VAL_MASKS_DIR,
            is_train=False
        )
        
        # ğŸ”¥ æ™ºèƒ½é‡‡æ ·å™¨
        train_sampler = self.train_dataset.get_weighted_sampler()
        
        # åˆ›å»ºæ•°æ®åŠ è½½å™¨
        self.train_loader = DataLoader(
            self.train_dataset,
            batch_size=config.BATCH_SIZE,
            sampler=train_sampler,
            num_workers=config.NUM_WORKERS,
            pin_memory=config.PIN_MEMORY,
            drop_last=True
        )
        
        self.val_loader = DataLoader(
            self.val_dataset,
            batch_size=config.BATCH_SIZE,
            shuffle=False,
            num_workers=config.NUM_WORKERS,
            pin_memory=config.PIN_MEMORY
        )
        
        logger.info(f"æ•°æ®å‡†å¤‡å®Œæ¯•ï¼")
        logger.info(f"  è®­ç»ƒæ ·æœ¬: {len(self.train_dataset)}")
        logger.info(f"  éªŒè¯æ ·æœ¬: {len(self.val_dataset)}")
        logger.info(f"  æ™ºèƒ½é‡‡æ ·: {'å·²å¯ç”¨' if train_sampler else 'æœªå¯ç”¨'}")
    
    def setup_training(self):
        """è®¾ç½®è®­ç»ƒç»„ä»¶"""
        logger.info("è€å“¥æ­£åœ¨é…ç½®è®­ç»ƒå‚æ•°...")
        
        # ğŸ”¥ åˆ†å±‚å­¦ä¹ ç‡ - ä¸åŒéƒ¨åˆ†ç”¨ä¸åŒå­¦ä¹ ç‡
        param_groups = [
            # SAM backbone - å°å­¦ä¹ ç‡
            {'params': [p for n, p in self.model.sam.named_parameters() if p.requires_grad], 
             'lr': config.LEARNING_RATE * 0.1},
            # åˆ†å‰²å¤´ - å¤§å­¦ä¹ ç‡  
            {'params': self.model.segmentation_head.parameters(), 
             'lr': config.LEARNING_RATE},
            # æ³¨æ„åŠ›æ¨¡å— - ä¸­ç­‰å­¦ä¹ ç‡
            {'params': self.model.attention.parameters(), 
             'lr': config.LEARNING_RATE * 0.5}
        ]
        
        self.optimizer = optim.AdamW(
            param_groups,
            weight_decay=config.WEIGHT_DECAY
        )
        
        # ğŸ¯ å­¦ä¹ ç‡è°ƒåº¦å™¨
        self.scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(
            self.optimizer,
            T_0=15,  # æ¯20ä¸ªepoché‡å¯ä¸€æ¬¡
            T_mult=2,  # é‡å¯å‘¨æœŸç¿»å€
            eta_min=1e-6
        )
        
        # ğŸ”¥ æ€æ‰‹çº§æŸå¤±å‡½æ•°
        self.criterion = KillerLoss(
            class_weights=self.current_weights,
            focal_alpha=config.FOCAL_ALPHA,
            focal_gamma=config.FOCAL_GAMMA
        )
        self.criterion.to(self.device)
        
        # æ™ºèƒ½æŒ‡æ ‡è®¡ç®—å™¨
        self.metrics = SmartMetrics(config.NUM_CLASSES, config.CLASS_NAMES)
        
        logger.info("è®­ç»ƒé…ç½®å®Œæ¯•ï¼å‡†å¤‡å¼€æˆ˜ï¼ğŸ”¥")
    
    def dynamic_weight_adjustment(self, val_metrics):
        """åŠ¨æ€è°ƒæ•´ç±»åˆ«æƒé‡ - è€å“¥çš„æ™ºèƒ½è°ƒå‚"""
        if not config.DYNAMIC_WEIGHT_UPDATE:
            return
        
        class_ious = val_metrics['class_ious']
        
        # ğŸ”¥ æ ¹æ®IoUè¡¨ç°åŠ¨æ€è°ƒæ•´æƒé‡
        new_weights = self.current_weights.copy()
        
        # ç—…ç¶ç±»åˆ«æƒé‡è°ƒæ•´ç­–ç•¥
        lesion_classes = [3, 4, 5]  # å£°å¸¦å°ç»“ã€ç™½æ–‘ã€ä¹³å¤´çŠ¶ç˜¤
        
        for i, class_name in enumerate(config.CLASS_NAMES):
            current_iou = class_ious.get(class_name, 0)
            
            if i in lesion_classes:
                # ç—…ç¶ç±»åˆ«ï¼šIoUè¶Šä½ï¼Œæƒé‡è¶Šé«˜
                if current_iou < 0.1:
                    new_weights[i] = min(new_weights[i] * 1.2, 50.0)  # æƒé‡å¢åŠ 20%ï¼Œä¸Šé™50
                elif current_iou > 0.3:
                    new_weights[i] = max(new_weights[i] * 0.9, 5.0)   # æƒé‡å‡å°‘10%ï¼Œä¸‹é™5
        
        # æ›´æ–°æƒé‡
        if new_weights != self.current_weights:
            self.current_weights = new_weights
            # é‡æ–°åˆ›å»ºæŸå¤±å‡½æ•°
            self.criterion = KillerLoss(
                class_weights=self.current_weights,
                focal_alpha=config.FOCAL_ALPHA,
                focal_gamma=config.FOCAL_GAMMA
            )
            self.criterion.to(self.device)
            
            logger.info("åŠ¨æ€è°ƒæ•´ç±»åˆ«æƒé‡ï¼")
            for i, (name, weight) in enumerate(zip(config.CLASS_NAMES, self.current_weights)):
                logger.info(f"  {name}: {weight:.2f}")

# ç»§ç»­ä¸‹ä¸€éƒ¨åˆ†...
def main():
    """è€å“¥çš„ä¸»å‡½æ•°"""
    logger.info("ğŸ”¥ğŸ”¥ğŸ”¥ è€å“¥çš„SAMä¼˜åŒ–è®­ç»ƒå¼€å§‹ï¼ğŸ”¥ğŸ”¥ğŸ”¥")
    
    # æ˜¾ç¤ºGPUä¿¡æ¯
    if torch.cuda.is_available():
        gpu_name = torch.cuda.get_device_name(0)
        gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3
        logger.info(f"è€å“¥çš„è£…å¤‡ï¼š{gpu_name} ({gpu_memory:.1f}GB)")
    else:
        logger.warning("æ²¡æœ‰GPUï¼Ÿè¿™å¯ä¸è¡Œï¼")
    
    # æ£€æŸ¥è·¯å¾„
    paths_to_check = [
        config.TRAIN_IMAGES_DIR, config.TRAIN_MASKS_DIR,
        config.VAL_IMAGES_DIR, config.VAL_MASKS_DIR,
        config.SAM_MODEL_PATH
    ]
    
    for path in paths_to_check:
        if not os.path.exists(path):
            logger.error(f"è·¯å¾„ä¸å­˜åœ¨ {path}")
            sys.exit(1)
    
    # æ‰“å°ä¼˜åŒ–ç­–ç•¥
    logger.info("è€å“¥çš„ä¼˜åŒ–ç­–ç•¥ï¼š")
    logger.info(f"  ğŸ”¥ Focal Loss: {'å¯ç”¨' if config.USE_FOCAL_LOSS else 'å…³é—­'}")
    logger.info(f"  ğŸ¯ Dice Loss: {'å¯ç”¨' if config.USE_DICE_LOSS else 'å…³é—­'}")
    logger.info(f"  ğŸ§  æ™ºèƒ½é‡‡æ ·: {'å¯ç”¨' if config.USE_SMART_SAMPLING else 'å…³é—­'}")
    logger.info(f"  ğŸ“ å¤šå°ºåº¦è®­ç»ƒ: {'å¯ç”¨' if config.USE_MULTI_SCALE_LOSS else 'å…³é—­'}")
    logger.info(f"  ğŸ›¡ï¸ æ ‡ç­¾å¹³æ»‘: {'å¯ç”¨' if config.USE_LABEL_SMOOTHING else 'å…³é—­'}")
    
    # æ‰“å°ç±»åˆ«æ˜ å°„
    logger.info("è€å“¥çš„ç±»åˆ«æ˜ å°„ï¼š")
    for original_id, new_id in config.ID_MAPPING.items():
        class_name = config.CLASS_NAMES[new_id]
        weight = config.INITIAL_CLASS_WEIGHTS[new_id]
        logger.info(f"  {original_id} -> {new_id} ({class_name}) æƒé‡:{weight}")
    
    # å¼€å§‹è®­ç»ƒ
    trainer = SuperTrainer()
    trainer.train()

# åœ¨SuperTrainerç±»ä¸­æ·»åŠ è®­ç»ƒæ–¹æ³•
def add_training_methods_to_trainer():
    """æ·»åŠ è®­ç»ƒæ–¹æ³•åˆ°SuperTrainerç±»"""
    
    def train_one_epoch(self, epoch):
        """è®­ç»ƒä¸€ä¸ªepoch - è€å“¥ç²¾å¿ƒè°ƒæ•™"""
        self.model.train()
        self.metrics.reset()
        
        running_loss = 0.0
        running_loss_dict = defaultdict(float)
        num_batches = 0
        
        # æ›´æ–°æ•°æ®é›†çš„epochï¼ˆç”¨äºå¤šå°ºåº¦è®­ç»ƒï¼‰
        self.train_dataset.current_epoch = epoch
        
        pbar = tqdm(self.train_loader, desc=f"Epoch {epoch+1}/{config.NUM_EPOCHS} [è®­ç»ƒ]")
        
        for batch_idx, (images, masks, filenames) in enumerate(pbar):
            images = images.to(self.device)
            masks = masks.to(self.device)
            
            # ğŸ”¥ æ··åˆç²¾åº¦è®­ç»ƒ
            if config.MIXED_PRECISION and self.scaler:
                with autocast():
                    predictions, _ = self.model(images)
                    loss, loss_dict = self.criterion(predictions, masks)
                    loss = loss / config.GRADIENT_ACCUMULATION_STEPS
                
                self.scaler.scale(loss).backward()
                
                if (batch_idx + 1) % config.GRADIENT_ACCUMULATION_STEPS == 0:
                    self.scaler.step(self.optimizer)
                    self.scaler.update()
                    self.optimizer.zero_grad()
            else:
                predictions, _ = self.model(images)
                loss, loss_dict = self.criterion(predictions, masks)
                loss = loss / config.GRADIENT_ACCUMULATION_STEPS
                
                loss.backward()
                
                if (batch_idx + 1) % config.GRADIENT_ACCUMULATION_STEPS == 0:
                    self.optimizer.step()
                    self.optimizer.zero_grad()
            
            # æ›´æ–°æŒ‡æ ‡
            self.metrics.update(predictions.detach(), masks)
            
            # è®°å½•æŸå¤±
            running_loss += loss.item()
            for key, value in loss_dict.items():
                running_loss_dict[key] += value
            num_batches += 1
            
            # æ›´æ–°è¿›åº¦æ¡
            if num_batches > 0:
                avg_loss = running_loss / num_batches * config.GRADIENT_ACCUMULATION_STEPS
                pbar.set_postfix({
                    'loss': f'{avg_loss:.4f}',
                    'lr': f'{self.optimizer.param_groups[0]["lr"]:.2e}'
                })
            
            # ğŸš€ å®šæœŸæ¸…ç†æ˜¾å­˜
            if batch_idx % config.CLEAR_CACHE_EVERY == 0:
                torch.cuda.empty_cache()
                gc.collect()
        
        # è®¡ç®—epochæŒ‡æ ‡
        epoch_metrics = self.metrics.compute()
        avg_loss = running_loss / num_batches * config.GRADIENT_ACCUMULATION_STEPS
        
        # è¯¦ç»†çš„æŸå¤±åˆ†è§£
        loss_breakdown = {}
        for key, value in running_loss_dict.items():
            loss_breakdown[key] = value / num_batches
        
        # æ›´æ–°å­¦ä¹ ç‡
        self.scheduler.step()
        
        return avg_loss, epoch_metrics, loss_breakdown
    
    def validate_one_epoch(self, epoch):
        """éªŒè¯ä¸€ä¸ªepoch - è€å“¥ä¸¥æ ¼æŠŠå…³"""
        self.model.eval()
        self.metrics.reset()
        
        running_loss = 0.0
        num_batches = 0
        
        pbar = tqdm(self.val_loader, desc=f"Epoch {epoch+1}/{config.NUM_EPOCHS} [éªŒè¯]")
        
        with torch.no_grad():
            for batch_idx, (images, masks, filenames) in enumerate(pbar):
                images = images.to(self.device)
                masks = masks.to(self.device)
                
                if config.MIXED_PRECISION:
                    with autocast():
                        predictions, _ = self.model(images)
                        loss, _ = self.criterion(predictions, masks)
                else:
                    predictions, _ = self.model(images)
                    loss, _ = self.criterion(predictions, masks)
                
                # æ›´æ–°æŒ‡æ ‡
                self.metrics.update(predictions, masks)
                running_loss += loss.item()
                num_batches += 1
                
                # æ›´æ–°è¿›åº¦æ¡
                if num_batches > 0:
                    avg_loss = running_loss / num_batches
                    pbar.set_postfix({'val_loss': f'{avg_loss:.4f}'})
        
        # è®¡ç®—epochæŒ‡æ ‡
        epoch_metrics = self.metrics.compute()
        avg_loss = running_loss / num_batches if num_batches > 0 else 0
        
        return avg_loss, epoch_metrics
    
    def print_epoch_summary(self, epoch, train_loss, train_metrics, val_loss, val_metrics, loss_breakdown):
        """æ‰“å°epochæ€»ç»“ - è€å“¥å¼æ±‡æŠ¥"""
        logger.info(f"\n{'='*60}")
        logger.info(f"ğŸ”¥ ç¬¬ {epoch+1} ä¸ªEpochæ€»ç»“ - è€å“¥æ±‡æŠ¥:")
        logger.info(f"{'='*60}")
        
        # åŸºç¡€æŒ‡æ ‡
        logger.info(f"ğŸ“Š æ•´ä½“è¡¨ç°:")
        logger.info(f"  è®­ç»ƒæŸå¤±: {train_loss:.4f} | éªŒè¯æŸå¤±: {val_loss:.4f}")
        logger.info(f"  è®­ç»ƒmIoU: {train_metrics['mIoU']:.4f} | éªŒè¯mIoU: {val_metrics['mIoU']:.4f}")
        logger.info(f"  è®­ç»ƒå‡†ç¡®ç‡: {train_metrics['accuracy']:.4f} | éªŒè¯å‡†ç¡®ç‡: {val_metrics['accuracy']:.4f}")
        
        # æŸå¤±åˆ†è§£
        logger.info(f"ğŸ” æŸå¤±åˆ†è§£:")
        for loss_name, loss_value in loss_breakdown.items():
            logger.info(f"  {loss_name}: {loss_value:.4f}")
        
        # ğŸ”¥ å„ç±»åˆ«è¯¦ç»†IoU - è€å“¥æœ€å…³å¿ƒçš„
        logger.info(f"ğŸ¯ å„ç±»åˆ«IoUè¡¨ç°:")
        for class_name, iou in val_metrics['class_ious'].items():
            status = ""
            if class_name in ['å£°å¸¦å°ç»“', 'å£°å¸¦ç™½æ–‘', 'å£°å¸¦ä¹³å¤´çŠ¶ç˜¤']:
                if iou < 0.1:
                    status = "ğŸ˜° éœ€è¦å…³æ³¨!"
                elif iou < 0.3:
                    status = "ğŸ˜ æœ‰å¾…æé«˜"
                elif iou < 0.5:
                    status = "ğŸ˜Š ä¸é”™"
                else:
                    status = "ğŸ”¥ ä¼˜ç§€!"
            else:
                if iou < 0.5:
                    status = "ğŸ˜ ä¸€èˆ¬"
                elif iou < 0.7:
                    status = "ğŸ˜Š ä¸é”™"
                else:
                    status = "ğŸ”¥ ä¼˜ç§€!"
            
            logger.info(f"  {class_name}: {iou:.4f} {status}")
        
        # ğŸš€ ç—…ç¶ä¸“é¡¹è¿›åº¦æŠ¥å‘Š
        if val_metrics['lesion_report']:
            logger.info(f"ğŸ¥ ç—…ç¶å­¦ä¹ è¿›åº¦:")
            lesion_names = {'sdxj': 'å£°å¸¦å°ç»“', 'sdbb': 'å£°å¸¦ç™½æ–‘', 'rtzl': 'å£°å¸¦ä¹³å¤´çŠ¶ç˜¤'}
            for lesion_code, report in val_metrics['lesion_report'].items():
                lesion_name = lesion_names.get(lesion_code, lesion_code)
                trend_emoji = "ğŸ“ˆ" if report['trend'] == 'improving' else "ğŸ“Š"
                logger.info(f"  {lesion_name}: {report['current_iou']:.4f} {trend_emoji}")
        
        # å­¦ä¹ ç‡ä¿¡æ¯
        current_lr = self.optimizer.param_groups[0]['lr']
        logger.info(f"ğŸ“š å½“å‰å­¦ä¹ ç‡: {current_lr:.2e}")
        
        logger.info(f"{'='*60}\n")
    
    def save_checkpoint(self, epoch, val_metrics, is_best=False):
        """ä¿å­˜æ£€æŸ¥ç‚¹"""
        checkpoint = {
            'epoch': epoch,
            'model_state_dict': self.model.state_dict(),
            'optimizer_state_dict': self.optimizer.state_dict(),
            'scheduler_state_dict': self.scheduler.state_dict(),
            'best_miou': self.best_miou,
            'metrics': val_metrics,
            'config': config.__dict__,
            'class_weights': self.current_weights
        }
        
        # ä¿å­˜å¸¸è§„æ£€æŸ¥ç‚¹
        if (epoch + 1) % config.SAVE_EVERY == 0:
            checkpoint_path = os.path.join(config.RESULTS_DIR, "models", f"checkpoint_epoch_{epoch+1:03d}.pth")
            torch.save(checkpoint, checkpoint_path)
            logger.info(f"æ£€æŸ¥ç‚¹å·²ä¿å­˜ {checkpoint_path}")
        
        # ä¿å­˜æœ€ä½³æ¨¡å‹
        if is_best:
            best_path = os.path.join(config.RESULTS_DIR, "models", "best_model.pth")
            torch.save(checkpoint, best_path)
            logger.info(f"ğŸ† æœ€ä½³æ¨¡å‹å·²ä¿å­˜ï¼mIoU: {val_metrics['mIoU']:.4f}")
    
    def save_training_plots(self):
        """ä¿å­˜è®­ç»ƒæ›²çº¿å›¾"""
        if not self.history['train_loss']:
            return
        
        plt.figure(figsize=(15, 10))
        
        # æŸå¤±æ›²çº¿
        plt.subplot(2, 3, 1)
        plt.plot(self.history['train_loss'], label='è®­ç»ƒæŸå¤±', color='red')
        plt.plot(self.history['val_loss'], label='éªŒè¯æŸå¤±', color='blue')
        plt.title('æŸå¤±æ›²çº¿')
        plt.xlabel('Epoch')
        plt.ylabel('Loss')
        plt.legend()
        plt.grid(True)
        
        # mIoUæ›²çº¿
        plt.subplot(2, 3, 2)
        plt.plot(self.history['train_miou'], label='è®­ç»ƒmIoU', color='red')
        plt.plot(self.history['val_miou'], label='éªŒè¯mIoU', color='blue')
        plt.title('mIoUæ›²çº¿')
        plt.xlabel('Epoch')
        plt.ylabel('mIoU')
        plt.legend()
        plt.grid(True)
        
        # ğŸ”¥ ç—…ç¶ç±»åˆ«IoUè¶‹åŠ¿ - è€å“¥ç‰¹åˆ¶
        colors = ['green', 'orange', 'purple']
        lesion_names = {'sdxj': 'å£°å¸¦å°ç»“', 'sdbb': 'å£°å¸¦ç™½æ–‘', 'rtzl': 'å£°å¸¦ä¹³å¤´çŠ¶ç˜¤'}
        
        for i, (lesion_code, color) in enumerate(zip(self.history['lesion_ious'].keys(), colors)):
            plt.subplot(2, 3, 3+i)
            if self.history['lesion_ious'][lesion_code]:
                plt.plot(self.history['lesion_ious'][lesion_code], color=color, linewidth=2)
                plt.title(f'{lesion_names[lesion_code]} IoUè¶‹åŠ¿')
                plt.xlabel('Validation Step')
                plt.ylabel('IoU')
                plt.grid(True)
        
        plt.tight_layout()
        plot_path = os.path.join(config.RESULTS_DIR, "training_curves.png")
        plt.savefig(plot_path, dpi=300, bbox_inches='tight')
        plt.close()
        
        logger.info(f"è®­ç»ƒæ›²çº¿å·²ä¿å­˜ {plot_path}")
    
    def train(self):
        """ä¸»è®­ç»ƒå¾ªç¯ - è€å“¥äº²è‡ªç£æˆ˜ï¼"""
        logger.info("ğŸš€ğŸš€ğŸš€ è€å“¥å¼€å§‹ç£æˆ˜è®­ç»ƒï¼ğŸš€ğŸš€ğŸš€")
        
        start_time = time.time()
        
        for epoch in range(config.NUM_EPOCHS):
            logger.info(f"\nğŸ”¥ ç¬¬ {epoch+1}/{config.NUM_EPOCHS} ä¸ªEpochå¼€å§‹ï¼")
            
            # è®­ç»ƒé˜¶æ®µ
            train_loss, train_metrics, loss_breakdown = self.train_one_epoch(epoch)
            
            # éªŒè¯é˜¶æ®µ
            if (epoch + 1) % config.EVAL_EVERY == 0:
                val_loss, val_metrics = self.validate_one_epoch(epoch)
                
                # æ‰“å°è¯¦ç»†æŠ¥å‘Š
                self.print_epoch_summary(epoch, train_loss, train_metrics, val_loss, val_metrics, loss_breakdown)
                
                # ğŸ”¥ åŠ¨æ€è°ƒæ•´æƒé‡
                self.dynamic_weight_adjustment(val_metrics)
                
                # è®°å½•å†å²
                self.history['train_loss'].append(train_loss)
                self.history['val_loss'].append(val_loss)
                self.history['train_miou'].append(train_metrics['mIoU'])
                self.history['val_miou'].append(val_metrics['mIoU'])
                
                # è®°å½•ç—…ç¶è¿›åº¦
                for lesion_code, report in val_metrics.get('lesion_report', {}).items():
                    if lesion_code in self.history['lesion_ious']:
                        self.history['lesion_ious'][lesion_code].append(report['current_iou'])
                
                # ğŸ† æ£€æŸ¥æ˜¯å¦æœ€ä½³æ¨¡å‹
                current_miou = val_metrics['mIoU']
                is_best = current_miou > self.best_miou
                
                if is_best:
                    self.best_miou = current_miou
                    self.patience_counter = 0
                    logger.info(f"ğŸ‰ æ–°çºªå½•ï¼mIoU: {self.best_miou:.4f}")
                else:
                    self.patience_counter += 1
                    logger.info(f"è€å¿ƒç­‰å¾…ä¸­... ({self.patience_counter}/{config.EARLY_STOPPING_PATIENCE})")
                
                # ä¿å­˜æ£€æŸ¥ç‚¹
                self.save_checkpoint(epoch, val_metrics, is_best)
                
                # æ—©åœæ£€æŸ¥
                if self.patience_counter >= config.EARLY_STOPPING_PATIENCE:
                    logger.info("æ²¡æœ‰æ”¹å–„ï¼Œæå‰ç»“æŸè®­ç»ƒï¼")
                    break
            
            # ä¿å­˜è®­ç»ƒå›¾è¡¨
            if (epoch + 1) % (config.SAVE_EVERY * 2) == 0:
                self.save_training_plots()
            
            # ğŸš€ æ˜¾å­˜æ¸…ç†
            torch.cuda.empty_cache()
            gc.collect()
        
        # è®­ç»ƒç»“æŸ
        total_time = time.time() - start_time
        logger.info(f"\nğŸŠğŸŠğŸŠ è®­ç»ƒå®Œæˆï¼ğŸŠğŸŠğŸŠ")
        logger.info(f"æ€»è€—æ—¶: {total_time/3600:.2f} å°æ—¶")
        logger.info(f"æœ€ä½³mIoU: {self.best_miou:.4f}")
        
        # ä¿å­˜æœ€ç»ˆç»“æœ
        self.save_training_plots()
        
        # ä¿å­˜è®­ç»ƒå†å²
        history_path = os.path.join(config.RESULTS_DIR, "training_history.json")
        with open(history_path, 'w', encoding='utf-8') as f:
            json.dump(self.history, f, indent=2, ensure_ascii=False)
        
        logger.info(f"ä¸€åˆ‡æå®šï¼ç»“æœä¿å­˜åœ¨ {config.RESULTS_DIR}")
    
    # åŠ¨æ€æ·»åŠ æ–¹æ³•åˆ°SuperTrainerç±»
    SuperTrainer.train_one_epoch = train_one_epoch
    SuperTrainer.validate_one_epoch = validate_one_epoch
    SuperTrainer.print_epoch_summary = print_epoch_summary
    SuperTrainer.save_checkpoint = save_checkpoint
    SuperTrainer.save_training_plots = save_training_plots
    SuperTrainer.train = train

# åœ¨ä¸»å‡½æ•°å‰è°ƒç”¨
add_training_methods_to_trainer()

if __name__ == "__main__":
    main() 