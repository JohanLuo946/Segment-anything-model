#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
SAMé€šç”¨ç—…ç¶æ‰¹é‡æµ‹è¯•è„šæœ¬ - æµ‹è¯•é›†æ•´ä½“Diceè®¡ç®— 
åŠŸèƒ½ï¼šåŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹ï¼Œå¯¹æ•´ä¸ªæµ‹è¯•é›†è¿›è¡Œé¢„æµ‹ï¼Œè®¡ç®—å¹³å‡Diceåˆ†æ•°ï¼ˆèƒŒæ™¯å’ŒæŒ‡å®šç—…ç¶ç±»ï¼‰ã€‚
é‡‡ç”¨test_fold_Dice_12class.pyçš„è®¡ç®—é€»è¾‘ï¼Œé€‚åº”2ç±»ã€‚
"""

import os
import numpy as np
import torch
import torch.nn.functional as F
import cv2
from torch.utils.data import Dataset, DataLoader
from tqdm import tqdm
from segment_anything import sam_model_registry
from collections import defaultdict

# ===== ğŸ’ª é…ç½®ç±»ï¼ˆä¸è®­ç»ƒè„šæœ¬ä¸€è‡´ï¼‰ =====
class TestConfig:
    IMAGE_SIZE = 1024
    NUM_CLASSES = 2
    BATCH_SIZE = 1  
    NUM_WORKERS = 4
    SAM_MODEL_TYPE = "vit_b"
    PIXEL_MEAN = [123.675, 116.28, 103.53]
    PIXEL_STD = [58.395, 57.12, 57.375]
    DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
    
    LESION_ID = 29  
    LESION_NAME = "å£°å¸¦ç™½æ–‘"  
    
    ID_MAPPING = {
        0: 0,          
        LESION_ID: 1,  
    }
    CLASS_NAMES = ["èƒŒæ™¯", LESION_NAME]
    
    LESION_CLASSES = [1]  # ç—…ç¶ç±»åˆ«

config = TestConfig()

class DSCEnhancedSAMModel(torch.nn.Module):
    """DSCå¢å¼ºSAMæ¨¡å‹ - ä¸train_2classes_v2.pyå®Œå…¨ä¸€è‡´"""
    
    def __init__(self, sam_model, num_classes):
        super().__init__()
        self.sam = sam_model
        self.num_classes = num_classes
        
        # å¢å¼ºçš„åˆ†å‰²å¤´ - ä¸ºDSCä¼˜åŒ–
        self.segmentation_head = torch.nn.Sequential(
            torch.nn.Conv2d(256, 128, kernel_size=3, padding=1),
            torch.nn.BatchNorm2d(128),
            torch.nn.ReLU(inplace=True),
            torch.nn.Dropout2d(0.1),  # æ·»åŠ dropouté˜²è¿‡æ‹Ÿåˆ
            
            torch.nn.Conv2d(128, 64, kernel_size=3, padding=1),
            torch.nn.BatchNorm2d(64),
            torch.nn.ReLU(inplace=True),
            torch.nn.Dropout2d(0.05),
            
            # æ·»åŠ æ®‹å·®è¿æ¥
            torch.nn.Conv2d(64, 32, kernel_size=3, padding=1),
            torch.nn.BatchNorm2d(32),
            torch.nn.ReLU(inplace=True),
            
            torch.nn.Conv2d(32, num_classes, kernel_size=1)
        )
        
        # å¢å¼ºæ³¨æ„åŠ›æœºåˆ¶
        self.attention = torch.nn.Sequential(
            torch.nn.Conv2d(256, 64, kernel_size=1),
            torch.nn.ReLU(inplace=True),
            torch.nn.Conv2d(64, 16, kernel_size=1),
            torch.nn.ReLU(inplace=True),
            torch.nn.Conv2d(16, 1, kernel_size=1),
            torch.nn.Sigmoid()
        )
        
        # è¾¹ç•Œç»†åŒ–æ¨¡å—
        self.boundary_refine = torch.nn.Sequential(
            torch.nn.Conv2d(num_classes, 16, kernel_size=3, padding=1),
            torch.nn.ReLU(inplace=True),
            torch.nn.Conv2d(16, num_classes, kernel_size=1),
            torch.nn.Tanh()  # ä½¿ç”¨tanhé™åˆ¶è¾“å‡ºèŒƒå›´
        )
    
    def forward(self, images):
        batch_size = images.shape[0]
        
        image_embeddings = self.sam.image_encoder(images)
        
        attention_map = self.attention(image_embeddings)
        enhanced_features = image_embeddings * attention_map
        
        segmentation_logits = self.segmentation_head(enhanced_features)
        
        # è¾¹ç•Œç»†åŒ–
        boundary_refinement = self.boundary_refine(segmentation_logits)
        refined_logits = segmentation_logits + 0.1 * boundary_refinement
        
        refined_logits = F.interpolate(
            refined_logits,
            size=(images.shape[2], images.shape[3]),
            mode="bilinear",
            align_corners=False,
        )
        
        return refined_logits

# ===== ğŸ¯ æµ‹è¯•æ•°æ®é›†ç±»ï¼ˆç®€åŒ–ç‰ˆï¼Œæ— å¢å¼º/é‡‡æ ·ï¼‰ =====
class TestDataset(Dataset):
    def __init__(self, images_dir, masks_dir):
        self.images_dir = images_dir
        self.masks_dir = masks_dir
        self.image_files = [f for f in os.listdir(images_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]
        print(f"æ‰¾åˆ° {len(self.image_files)} ä¸ªæµ‹è¯•å›¾åƒ")
        
        # æ–°å¢ï¼šè‡ªåŠ¨è¿‡æ»¤ï¼Œåªä¿ç•™åŒ…å«æŒ‡å®šLESION_IDçš„å›¾åƒ
        self.filter_lesion_only()
    
    def filter_lesion_only(self):
        """è¿‡æ»¤æµ‹è¯•é›†ï¼Œåªä¿ç•™æ©ç ä¸­åŒ…å«æŒ‡å®šLESION_IDçš„å›¾åƒï¼Œå¹¶ç»Ÿè®¡æ•°é‡"""
        filtered_files = []
        for file in tqdm(self.image_files, desc=f"è¿‡æ»¤æµ‹è¯•é›†ï¼ˆåªä¿ç•™å«ID={config.LESION_ID}çš„å›¾åƒï¼‰"):
            mask_file = file.replace('.jpg', '.png').replace('.jpeg', '.png')
            mask_path = os.path.join(self.masks_dir, mask_file)
            mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)
            if mask is not None and config.LESION_ID in np.unique(mask):
                filtered_files.append(file)
        
        original_count = len(self.image_files)
        self.image_files = filtered_files
        filtered_count = len(self.image_files)
        
        print(f"è¿‡æ»¤å‰æµ‹è¯•é›†æ•°é‡: {original_count}")
        print(f"è¿‡æ»¤åæµ‹è¯•é›†æ•°é‡ï¼ˆå«ID={config.LESION_ID}ï¼‰: {filtered_count}")
        if filtered_count == 0:
            print(f"è­¦å‘Šï¼šè¿‡æ»¤åæµ‹è¯•é›†ä¸ºç©ºï¼è¯·æ£€æŸ¥æ•°æ®ä¸­æ˜¯å¦åŒ…å«ID={config.LESION_ID}ã€‚")
    
    def __len__(self):
        return len(self.image_files)
    
    def __getitem__(self, idx):
        image_file = self.image_files[idx]
        image_path = os.path.join(self.images_dir, image_file)
        image = cv2.imread(image_path)
        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        
        mask_file = image_file.replace('.jpg', '.png').replace('.jpeg', '.png')
        mask_path = os.path.join(self.masks_dir, mask_file)
        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)
        
        # åº”ç”¨IDæ˜ å°„ï¼ˆå…¶ä»–ç±»è½¬ä¸ºèƒŒæ™¯ï¼‰
        mapped_mask = np.zeros_like(mask)
        for original_id, new_id in config.ID_MAPPING.items():
            mapped_mask[mask == original_id] = new_id
        unknown_mask = ~np.isin(mask, list(config.ID_MAPPING.keys()))
        mapped_mask[unknown_mask] = 0
        
        # è°ƒæ•´å¤§å°
        image = cv2.resize(image, (config.IMAGE_SIZE, config.IMAGE_SIZE))
        mask = cv2.resize(mapped_mask, (config.IMAGE_SIZE, config.IMAGE_SIZE), interpolation=cv2.INTER_NEAREST)
        
        # è½¬æ¢ä¸ºtensor
        image = torch.from_numpy(image).permute(2, 0, 1).float() / 255.0
        mask = torch.from_numpy(mask).long()
        
        # æ ‡å‡†åŒ–
        mean = torch.tensor(config.PIXEL_MEAN).view(3, 1, 1) / 255.0
        std = torch.tensor(config.PIXEL_STD).view(3, 1, 1) / 255.0
        image = (image - mean) / std
        
        return image, mask

# ===== ğŸ“Š è¯„ä¼°æŒ‡æ ‡è®¡ç®—ç±»ï¼ˆé€‚åº”2ç±»ï¼ŒåŸºäºtest_fold_Dice_12class.pyï¼‰ =====
class ComprehensiveMetrics:
    """ç»¼åˆè¯„ä¼°æŒ‡æ ‡è®¡ç®—ç±» - æ”¯æŒ2ç±»è¯„ä¼°"""
    
    def __init__(self):
        # å¤šç»´åº¦è¯„ä¼°æŒ‡æ ‡
        self.pure_lesion_metrics = defaultdict(list)   # çº¯ç—…ç¶è¯„ä¼°ï¼šåªè€ƒè™‘ç—…ç¶åŒºåŸŸçš„æŒ‡æ ‡
        
        # æ–°å¢ï¼šæ¯å¼ å›¾åƒçš„æ•´ä½“microå’ŒmacroæŒ‡æ ‡
        self.whole_image_dice_list = []  # æ•´å¼ å›¾åƒçš„Dice
        self.whole_image_lesion_dice_list = []  # æ•´å¼ å›¾åƒçš„ç—…ç¶Dice
    
    def compute_metrics(self, pred: np.ndarray, target: np.ndarray) -> tuple:
        """è®¡ç®—Diceå’ŒIoU"""
        intersection = np.logical_and(pred, target).sum()
        pred_sum = pred.sum()
        target_sum = target.sum()
        
        if pred_sum + target_sum == 0:
            return 1.0, 1.0  # å®Œå…¨åŒ¹é…
        
        if pred_sum == 0 or target_sum == 0:
            return 0.0, 0.0  # å®Œå…¨ä¸åŒ¹é…
            
        dice = 2.0 * intersection / (pred_sum + target_sum)
        union = pred_sum + target_sum - intersection
        iou = intersection / union
        
        return float(dice), float(iou)
    
    def compute_pure_lesion_metrics(self, pred: np.ndarray, target: np.ndarray, lesion_mask: np.ndarray) -> tuple:
        """è®¡ç®—çº¯ç—…ç¶åŒºåŸŸçš„Diceå’ŒIoU"""
        if not lesion_mask.any():
            return 0.0, 0.0
            
        pred_lesion = pred[lesion_mask]
        target_lesion = target[lesion_mask]
        
        return self.compute_metrics(pred_lesion, target_lesion)
    
    def update(self, pred: np.ndarray, target: np.ndarray):
        """æ›´æ–°è¯„ä¼°æŒ‡æ ‡"""
        # è·å–å®é™…å­˜åœ¨çš„ç±»åˆ«ï¼ˆåŒ…æ‹¬èƒŒæ™¯ï¼‰
        present_classes = np.unique(target)
        
        # åˆ›å»ºç—…ç¶åŒºåŸŸæ©ç ï¼ˆæ‰€æœ‰ç—…ç¶ç±»åˆ«çš„å¹¶é›†ï¼‰
        lesion_mask = np.zeros_like(target, dtype=bool)
        for cls_id in config.LESION_CLASSES:
            if cls_id in present_classes:
                lesion_mask |= (target == cls_id)
        
        # è®¡ç®—æ¯ä¸ªå­˜åœ¨ç±»åˆ«çš„æŒ‡æ ‡
        total_inter = 0
        total_pred = 0
        total_gt = 0
        
        for cls_id in present_classes:
            pred_mask = (pred == cls_id)
            target_mask = (target == cls_id)
            
            # ç”¨äºwhole_image_dice (micro)
            inter = np.logical_and(pred_mask, target_mask).sum()
            p_sum = pred_mask.sum()
            g_sum = target_mask.sum()
            total_inter += inter
            total_pred += p_sum
            total_gt += g_sum
            
            # 2. å¦‚æœæ˜¯ç—…ç¶ç±»åˆ«ï¼Œè®¡ç®—é¢å¤–æŒ‡æ ‡
            if cls_id in config.LESION_CLASSES and target_mask.sum() > 0:
                # è®¡ç®—çº¯ç—…ç¶åŒºåŸŸçš„æŒ‡æ ‡
                pure_dice, pure_iou = self.compute_pure_lesion_metrics(
                    pred_mask, target_mask, lesion_mask)
                self.pure_lesion_metrics[int(cls_id)].append({
                    'dice': pure_dice,
                    'iou': pure_iou
                })
        
        # è®¡ç®—æ•´å¼ å›¾åƒçš„dice
        if present_classes.size > 0:
            # whole_image_dice (micro)
            if total_pred + total_gt > 0:
                whole_image_dice = 2.0 * total_inter / (total_pred + total_gt)
            else:
                whole_image_dice = 1.0
            self.whole_image_dice_list.append(whole_image_dice)
        
        lesion_present = [cls for cls in present_classes if cls in config.LESION_CLASSES]
        if lesion_present:
            lesion_inter = 0
            lesion_pred = 0
            lesion_gt = 0
            
            for cls_id in lesion_present:
                pred_mask = (pred == cls_id)
                target_mask = (target == cls_id)
                inter = np.logical_and(pred_mask, target_mask).sum()
                p_sum = pred_mask.sum()
                g_sum = target_mask.sum()
                lesion_inter += inter
                lesion_pred += p_sum
                lesion_gt += g_sum
            
            # whole_image_lesion_dice (micro for lesions)
            if lesion_pred + lesion_gt > 0:
                whole_image_lesion_dice = 2.0 * lesion_inter / (lesion_pred + lesion_gt)
            else:
                whole_image_lesion_dice = 1.0
            self.whole_image_lesion_dice_list.append(whole_image_lesion_dice)

    def get_metrics(self):
        metrics = {
            'per_class': {},
            'overall': {},
            'lesion_overall': {}
        }
        
        for cls_id in self.pure_lesion_metrics.keys():
            pure_scores = self.pure_lesion_metrics[cls_id]
            pure_dice = np.mean([s['dice'] for s in pure_scores])
            pure_iou = np.mean([s['iou'] for s in pure_scores])
            pure_dice_std = np.std([s['dice'] for s in pure_scores])
            pure_iou_std = np.std([s['iou'] for s in pure_scores])
            
            metrics['per_class'][cls_id] = {
                'pure_lesion_dice': float(pure_dice),
                'pure_lesion_dice_std': float(pure_dice_std),
                'pure_lesion_iou': float(pure_iou),
                'pure_lesion_iou_std': float(pure_iou_std),
            }
        
        metrics['overall'] = {
            'whole_image_dice': float(np.mean(self.whole_image_dice_list)) if self.whole_image_dice_list else 0.0,
            'whole_image_dice_std': float(np.std(self.whole_image_dice_list)) if self.whole_image_dice_list else 0.0,
        }
        
        metrics['lesion_overall'] = {
            'whole_image_lesion_dice': float(np.mean(self.whole_image_lesion_dice_list)) if self.whole_image_lesion_dice_list else 0.0,
            'whole_image_lesion_dice_std': float(np.std(self.whole_image_lesion_dice_list)) if self.whole_image_lesion_dice_list else 0.0,
        }
        
        return metrics

# ===== ğŸ” åŠ è½½æ¨¡å‹ =====
def load_model(model_path, sam_checkpoint):
    sam = sam_model_registry[config.SAM_MODEL_TYPE](checkpoint=sam_checkpoint)
    model = DSCEnhancedSAMModel(sam, config.NUM_CLASSES)
    checkpoint = torch.load(model_path, map_location=config.DEVICE)
    model.load_state_dict(checkpoint['model_state_dict'])
    model.to(config.DEVICE)
    model.eval()
    print(f"æ¨¡å‹åŠ è½½æˆåŠŸ: {model_path}")
    return model

# ===== ä¸»å‡½æ•°ï¼šæ‰¹é‡æµ‹è¯•å¹¶è®¡ç®—å¹³å‡Dice =====
def main():
    # åœ¨IDEä¸­ç¼–è¾‘ä»¥ä¸‹è·¯å¾„å˜é‡ï¼Œç„¶åç›´æ¥è¿è¡Œè„šæœ¬
    test_images_dir = "/root/autodl-tmp/SAM/sdbb/test/images"  
    test_masks_dir = "/root/autodl-tmp/SAM/sdbb/test/masks"    
    model_path = "/root/autodl-tmp/SAM/results/models/dsc_enhanced_sdbb_4/models/best_model_lesion_dice.pth"  
    sam_checkpoint = "/root/autodl-tmp/SAM/pre_models/sam_vit_b_01ec64.pth"  
    
    # åŠ è½½æ¨¡å‹
    model = load_model(model_path, sam_checkpoint)
    
    # åŠ è½½æ•°æ®é›†
    test_dataset = TestDataset(test_images_dir, test_masks_dir)
    test_loader = DataLoader(test_dataset, batch_size=config.BATCH_SIZE, num_workers=config.NUM_WORKERS, shuffle=False)
    
    # åˆå§‹åŒ–è¯„ä¼°å™¨
    metrics_calc = ComprehensiveMetrics()
    
    print(f"\nå¼€å§‹æµ‹è¯•ï¼Œå…± {len(test_dataset)} ä¸ªæ ·æœ¬...")
    
    with torch.no_grad():
        for images, masks in tqdm(test_loader, desc="æµ‹è¯•è¿›åº¦"):
            images = images.to(config.DEVICE)
            masks = masks.cpu().numpy()  # [B, H, W]
            
            logits = model(images)
            probs = torch.softmax(logits, dim=1)
            preds = torch.argmax(probs, dim=1).cpu().numpy()  # [B, H, W]
            
            for i in range(len(preds)):
                pred = preds[i]
                target = masks[i]
                
                # æ›´æ–°è¯„ä¼°æŒ‡æ ‡
                metrics_calc.update(pred, target)
    
    # è·å–è¯„ä¼°ç»“æœ
    results = metrics_calc.get_metrics()
    
    print(f"\n{'='*60}")
    print(f"ğŸ¯ DSCæµ‹è¯•ç»“æœæ€»ç»“")
    print(f"{'='*60}")
    
    # æ˜¾ç¤ºç—…ç¶ç±»åˆ«æŒ‡æ ‡
    for class_id in config.LESION_CLASSES:
        if class_id in results['per_class']:
            cls_results = results['per_class'][class_id]
            
            print(f"\nğŸ“Š {config.LESION_NAME} ç±»åˆ«æŒ‡æ ‡:")
            print(f"  pure_lesion_dice: {cls_results['pure_lesion_dice']:.4f} Â± {cls_results['pure_lesion_dice_std']:.4f}")
            print(f"  pure_lesion_iou:  {cls_results['pure_lesion_iou']:.4f} Â± {cls_results['pure_lesion_iou_std']:.4f}")
    
    # æ•´ä½“æŒ‡æ ‡
    print(f"\nğŸ† æ•´ä½“å¹³å‡æŒ‡æ ‡:")
    print(f"  whole_image_dice: {results['overall']['whole_image_dice']:.4f} Â± {results['overall']['whole_image_dice_std']:.4f}")
    
    # ç—…ç¶ä¸“é¡¹æŒ‡æ ‡
    print(f"\nğŸ¯ ç—…ç¶ä¸“é¡¹è¡¨ç°:")
    print(f"  whole_image_lesion_dice: {results['lesion_overall']['whole_image_lesion_dice']:.4f} Â± {results['lesion_overall']['whole_image_lesion_dice_std']:.4f}")
    
    print(f"\n{'='*60}")
    print(f"æµ‹è¯•å®Œæˆï¼æ€»æ ·æœ¬æ•°: {len(test_dataset)}")
    print(f"{'='*60}")

if __name__ == "__main__":
    main()